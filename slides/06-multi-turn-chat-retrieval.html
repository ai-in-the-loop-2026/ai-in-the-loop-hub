<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.24">

  <meta name="dcterms.date" content="2026-02-03">
  <title>Creating with AI in the Loop – Multi-turn Chat and Document Retrieval</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-0fde88a82f0356838740f155f1088782.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Multi-turn Chat and Document Retrieval</h1>

<div class="quarto-title-authors">
</div>

  <p class="date">2026-02-03</p>
</section>
<section id="todays-goals" class="slide level2">
<h2>Today’s goals</h2>
<ul>
<li>Understand how multi-turn chat works with <code>MessagesState</code></li>
<li>Build a simple chatbot that maintains conversation history</li>
<li>Learn to load and chunk documents using LangChain</li>
<li>Implement keyword search with <code>BM25Retriever</code></li>
<li>Combine chat + search into a document Q&amp;A agent</li>
</ul>
</section>
<section id="single-turn-vs-multi-turn" class="slide level2">
<h2>Single-turn vs multi-turn</h2>
<div style="text-align: center;">
<p><img data-src="images/06-single-vs-multi-turn.png" style="width:100.0%"></p>
</div>
<!-- IMAGE: ![](images/06-single-vs-multi-turn.png){width=75%}

     DESCRIPTION: Side-by-side comparison of single-turn and multi-turn conversation patterns.

     PROMPT FOR NANO BANANA PRO: Create a diagram with two panels side by side.
     LEFT PANEL labeled "Single-turn": Three boxes in a row with rightward arrows:
     [User] → [LLM] → [Response]. Below, text: "No memory between requests".
     RIGHT PANEL labeled "Multi-turn": Show two rows stacked vertically, labeled "Turn 1"
     and "Turn 2". Each row has: [Message] → [LLM] → [Response]. On the right side, show
     a "History" box. After Turn 1, the History box contains "Msg 1, Resp 1". An arrow goes
     from History into Turn 2's LLM. After Turn 2, the History box contains "Msg 1, Resp 1,
     Msg 2, Resp 2". Use soft blue and green colors. Clean boxes, minimal style. -->
</section>
<section id="how-chat-history-works" class="slide level2">
<h2>How chat history works</h2>
<p>When you use ChatGPT, Claude, or Gemini, the interface:</p>
<ol type="1">
<li><strong>Stores</strong> all previous messages (yours and the model’s)</li>
<li><strong>Sends</strong> the entire history with each new request</li>
<li><strong>Appends</strong> the new response to the history</li>
</ol>
<p>The model doesn’t “remember”—it re-reads the full conversation every time.</p>
</section>
<section id="messagesstate-revisited" class="slide level2">
<h2><code>MessagesState</code> revisited</h2>
<p>In deck 05, we used <code>MessagesState</code> for tool calling. Let’s look closer:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">from</span> typing <span class="im">import</span> Annotated</span>
<span id="cb1-2"><a></a><span class="im">from</span> typing_extensions <span class="im">import</span> TypedDict</span>
<span id="cb1-3"><a></a><span class="im">from</span> langgraph.graph.message <span class="im">import</span> AnyMessage, add_messages</span>
<span id="cb1-4"><a></a></span>
<span id="cb1-5"><a></a><span class="co"># MessagesState (from langgraph.graph) is defined as:</span></span>
<span id="cb1-6"><a></a><span class="kw">class</span> MessagesState(TypedDict):</span>
<span id="cb1-7"><a></a>    messages: Annotated[<span class="bu">list</span>[AnyMessage], add_messages]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p><code>Annotated</code> is standard Python for attaching metadata to type hints. Here, <code>add_messages</code> is the metadata — LangGraph uses it as a reducer that appends messages instead of replacing them. <code>AnyMessage</code> covers <code>HumanMessage</code>, <code>AIMessage</code>, <code>SystemMessage</code>, <code>ToolMessage</code>, etc.</p>
</div>
</div>
</div>
</section>
<section id="the-append-behavior" class="slide level2">
<h2>The append behavior</h2>
<p>When a node returns <code>{"messages": [new_msg]}</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="co"># State before</span></span>
<span id="cb2-2"><a></a>{<span class="st">"messages"</span>: [msg1, msg2]}</span>
<span id="cb2-3"><a></a></span>
<span id="cb2-4"><a></a><span class="co"># Node returns</span></span>
<span id="cb2-5"><a></a>{<span class="st">"messages"</span>: [msg3]}</span>
<span id="cb2-6"><a></a></span>
<span id="cb2-7"><a></a><span class="co"># State after (messages APPENDED, not replaced)</span></span>
<span id="cb2-8"><a></a>{<span class="st">"messages"</span>: [msg1, msg2, msg3]}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This is what enables multi-turn conversation—history accumulates automatically.</p>
<p>You saw this pattern in deck 05: messages accumulated through the tool loop (human → AI → tool → AI).</p>
</section>
<section id="simple-chatbot-complete-example" class="slide level2">
<h2>Simple chatbot: complete example</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a><span class="im">from</span> langchain_google_genai <span class="im">import</span> ChatGoogleGenerativeAI</span>
<span id="cb3-2"><a></a><span class="im">from</span> langgraph.graph <span class="im">import</span> StateGraph, MessagesState, START, END</span>
<span id="cb3-3"><a></a></span>
<span id="cb3-4"><a></a>llm <span class="op">=</span> ChatGoogleGenerativeAI(model<span class="op">=</span><span class="st">"gemini-2.5-flash"</span>)</span>
<span id="cb3-5"><a></a></span>
<span id="cb3-6"><a></a><span class="kw">def</span> chatbot(state: MessagesState):</span>
<span id="cb3-7"><a></a>    response <span class="op">=</span> llm.invoke(state[<span class="st">"messages"</span>])</span>
<span id="cb3-8"><a></a>    <span class="cf">return</span> {<span class="st">"messages"</span>: [response]}</span>
<span id="cb3-9"><a></a></span>
<span id="cb3-10"><a></a>graph <span class="op">=</span> StateGraph(MessagesState)</span>
<span id="cb3-11"><a></a>graph.add_node(<span class="st">"chatbot"</span>, chatbot)</span>
<span id="cb3-12"><a></a>graph.add_edge(START, <span class="st">"chatbot"</span>)</span>
<span id="cb3-13"><a></a>graph.add_edge(<span class="st">"chatbot"</span>, END)</span>
<span id="cb3-14"><a></a>app <span class="op">=</span> graph.<span class="bu">compile</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>No tools, no loops—just a model that responds to messages.</p>
</section>
<section id="running-the-chatbot" class="slide level2">
<h2>Running the chatbot</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a><span class="im">from</span> langchain_core.messages <span class="im">import</span> HumanMessage</span>
<span id="cb4-2"><a></a></span>
<span id="cb4-3"><a></a><span class="co"># First turn</span></span>
<span id="cb4-4"><a></a>result <span class="op">=</span> app.invoke({<span class="st">"messages"</span>: [HumanMessage(content<span class="op">=</span><span class="st">"Hi, I'm Alex."</span>)]})</span>
<span id="cb4-5"><a></a><span class="bu">print</span>(result[<span class="st">"messages"</span>][<span class="op">-</span><span class="dv">1</span>].content)</span>
<span id="cb4-6"><a></a><span class="co"># "Hello Alex! Nice to meet you. How can I help you today?"</span></span>
<span id="cb4-7"><a></a></span>
<span id="cb4-8"><a></a><span class="co"># Second turn — pass the full history</span></span>
<span id="cb4-9"><a></a>result <span class="op">=</span> app.invoke({<span class="st">"messages"</span>: result[<span class="st">"messages"</span>] <span class="op">+</span> [</span>
<span id="cb4-10"><a></a>    HumanMessage(content<span class="op">=</span><span class="st">"What's my name?"</span>)</span>
<span id="cb4-11"><a></a>]})</span>
<span id="cb4-12"><a></a><span class="bu">print</span>(result[<span class="st">"messages"</span>][<span class="op">-</span><span class="dv">1</span>].content)</span>
<span id="cb4-13"><a></a><span class="co"># "Your name is Alex!"</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>The model “remembers” because we passed the full conversation history.</p>
</section>
<section id="adding-a-system-prompt" class="slide level2">
<h2>Adding a system prompt</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a><span class="im">from</span> langchain_core.messages <span class="im">import</span> SystemMessage</span>
<span id="cb5-2"><a></a></span>
<span id="cb5-3"><a></a>SYSTEM_PROMPT <span class="op">=</span> <span class="st">"You are a helpful assistant. Be concise and friendly."</span></span>
<span id="cb5-4"><a></a></span>
<span id="cb5-5"><a></a><span class="kw">def</span> chatbot(state: MessagesState):</span>
<span id="cb5-6"><a></a>    <span class="co"># Prepend system message to the conversation</span></span>
<span id="cb5-7"><a></a>    messages <span class="op">=</span> [SystemMessage(content<span class="op">=</span>SYSTEM_PROMPT)] <span class="op">+</span> state[<span class="st">"messages"</span>]</span>
<span id="cb5-8"><a></a>    response <span class="op">=</span> llm.invoke(messages)</span>
<span id="cb5-9"><a></a>    <span class="cf">return</span> {<span class="st">"messages"</span>: [response]}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>The system message sets the model’s behavior but isn’t stored in state — if we stored it, <code>add_messages</code> would accumulate duplicates each turn.</p>
</section>
<section id="why-this-matters" class="slide level2">
<h2>Why this matters</h2>
<p>Multi-turn chat enables:</p>
<ul>
<li><strong>Context awareness</strong> — refer to earlier parts of the conversation</li>
<li><strong>Complex tasks</strong> — break problems into multiple exchanges</li>
</ul>
<p><strong>Limitation:</strong> The context window is finite. Very long conversations must be summarized or truncated.</p>
</section>
<section id="part-2-document-retrieval" class="slide level2">
<h2>Part 2: Document Retrieval</h2>
</section>
<section id="the-retrieval-problem" class="slide level2">
<h2>The retrieval problem</h2>
<p>LLMs learn patterns, not exact copies. They can’t reliably quote documents — even public ones from training data.</p>
<p>And they have no access to private documents or anything after their training cutoff.</p>
<p><strong>Solution:</strong> Give the model access to documents at query time.</p>
</section>
<section id="the-retrieval-pipeline" class="slide level2">
<h2>The retrieval pipeline</h2>
<div style="text-align: center;">
<p><img data-src="images/06-retrieval-pipeline.png" style="width:90.0%"></p>
</div>
<!-- IMAGE: ![](images/06-retrieval-pipeline.png){width=80%}

     DESCRIPTION: Horizontal pipeline showing the retrieval flow from documents to search results.

     PROMPT FOR NANO BANANA PRO: Create a horizontal pipeline diagram showing document retrieval
     flow. Four stages connected by arrows: "Load" (folder icon) → "Chunk" (scissors icon) →
     "Retriever" (filter icon) → "Search" (magnifying glass returning results).
     Clean technical style with soft colors. -->
<p>A <strong>retriever</strong> takes a query and returns relevant chunks from your documents.</p>
<p>Today we’ll use <strong>keyword search</strong>. Semantic search comes later.</p>
</section>
<section id="document-loaders" class="slide level2">
<h2>Document loaders</h2>
<p>LangChain provides loaders for many formats:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="im">from</span> langchain_community.document_loaders <span class="im">import</span> TextLoader, PyPDFLoader</span>
<span id="cb6-2"><a></a></span>
<span id="cb6-3"><a></a><span class="co"># Load a single text file (one Document for the whole file)</span></span>
<span id="cb6-4"><a></a>loader <span class="op">=</span> TextLoader(<span class="st">"readme.txt"</span>)</span>
<span id="cb6-5"><a></a>docs <span class="op">=</span> loader.load()</span>
<span id="cb6-6"><a></a></span>
<span id="cb6-7"><a></a><span class="co"># Load a PDF (one Document per page)</span></span>
<span id="cb6-8"><a></a>loader <span class="op">=</span> PyPDFLoader(<span class="st">"report.pdf"</span>)</span>
<span id="cb6-9"><a></a>docs <span class="op">=</span> loader.load()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Each loader returns a list of <code>Document</code> objects with <code>page_content</code> and <code>metadata</code>.</p>
<p>Other loaders include CSV, JSON, HTML, Word docs, and <a href="https://docs.langchain.com/oss/python/integrations/document_loaders">many more</a>. Some are specialized for extracting tables, formulas, or structured data.</p>
</section>
<section id="loading-directories" class="slide level2">
<h2>Loading directories</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a><span class="im">from</span> langchain_community.document_loaders <span class="im">import</span> DirectoryLoader, TextLoader</span>
<span id="cb7-2"><a></a></span>
<span id="cb7-3"><a></a><span class="co"># Load all .txt files from a directory</span></span>
<span id="cb7-4"><a></a>loader <span class="op">=</span> DirectoryLoader(</span>
<span id="cb7-5"><a></a>    <span class="st">"./docs"</span>,</span>
<span id="cb7-6"><a></a>    glob<span class="op">=</span><span class="st">"**/*.txt"</span>,</span>
<span id="cb7-7"><a></a>    loader_cls<span class="op">=</span>TextLoader</span>
<span id="cb7-8"><a></a>)</span>
<span id="cb7-9"><a></a>documents <span class="op">=</span> loader.load()</span>
<span id="cb7-10"><a></a></span>
<span id="cb7-11"><a></a><span class="bu">print</span>(<span class="ss">f"Loaded </span><span class="sc">{</span><span class="bu">len</span>(documents)<span class="sc">}</span><span class="ss"> documents"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>The <code>glob</code> pattern controls which files to include. Here, <code>**/*.txt</code> matches all <code>.txt</code> files in the directory and all subdirectories.</p>
</section>
<section id="why-chunking" class="slide level2">
<h2>Why chunking?</h2>
<p>Documents are often too long to:</p>
<ol type="1">
<li><strong>Fit in context</strong> — models have token limits</li>
<li><strong>Be relevant</strong> — a 100-page doc isn’t all relevant to one question</li>
</ol>
<p><strong>Chunking</strong> splits documents into smaller pieces so we can retrieve only what’s relevant.</p>
</section>
<section id="text-splitters" class="slide level2">
<h2>Text splitters</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a><span class="im">from</span> langchain_text_splitters <span class="im">import</span> RecursiveCharacterTextSplitter</span>
<span id="cb8-2"><a></a></span>
<span id="cb8-3"><a></a>splitter <span class="op">=</span> RecursiveCharacterTextSplitter(</span>
<span id="cb8-4"><a></a>    chunk_size<span class="op">=</span><span class="dv">1000</span>,      <span class="co"># Target size in characters</span></span>
<span id="cb8-5"><a></a>    chunk_overlap<span class="op">=</span><span class="dv">100</span>     <span class="co"># Overlap between chunks</span></span>
<span id="cb8-6"><a></a>)</span>
<span id="cb8-7"><a></a></span>
<span id="cb8-8"><a></a>chunks <span class="op">=</span> splitter.split_documents(documents)</span>
<span id="cb8-9"><a></a><span class="bu">print</span>(<span class="ss">f"Split into </span><span class="sc">{</span><span class="bu">len</span>(chunks)<span class="sc">}</span><span class="ss"> chunks"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><code>RecursiveCharacterTextSplitter</code> tries separators in order: <code>"\n\n"</code> → <code>"\n"</code> → <code>" "</code> → <code>""</code>. If a chunk is still too big, it recursively re-splits using the next separator. (Tries paragraph breaks first, then lines, then words, then characters)</p>
</section>
<section id="preparing-documents-for-chunking" class="slide level2">
<h2>Preparing documents for chunking</h2>
<p>Loaders return documents, but you may need to restructure before chunking:</p>
<ul>
<li><strong>Combine</strong>: Join PDF pages into one text so chunks can cross page boundaries</li>
<li><strong>Split</strong>: Separate chapters or sections so chunks don’t cross logical boundaries</li>
</ul>
<p>The right approach depends on your document structure and retrieval needs.</p>
</section>
<section id="whats-in-a-chunk" class="slide level2">
<h2>What’s in a chunk?</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>chunk <span class="op">=</span> chunks[<span class="dv">0</span>]</span>
<span id="cb9-2"><a></a></span>
<span id="cb9-3"><a></a><span class="bu">print</span>(chunk.page_content)   <span class="co"># The text content</span></span>
<span id="cb9-4"><a></a><span class="bu">print</span>(chunk.metadata)       <span class="co"># Source file, location, etc.</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<pre><code># Output
"This document describes the project architecture..."

{'source': './docs/architecture.txt', 'start_index': 0}</code></pre>
<p>Metadata helps track where each chunk came from.</p>
</section>
<section id="keyword-search-with-bm25" class="slide level2">
<h2>Keyword search with BM25</h2>
<p><strong>BM25</strong> (Best Matching 25) is a classic keyword search algorithm:</p>
<ul>
<li>Matches chunks containing query terms</li>
<li>Ranks by term frequency, normalized by chunk length (so longer chunks don’t have an unfair advantage)</li>
<li>No neural network — fast and interpretable</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a><span class="im">from</span> langchain_community.retrievers <span class="im">import</span> BM25Retriever</span>
<span id="cb11-2"><a></a></span>
<span id="cb11-3"><a></a>retriever <span class="op">=</span> BM25Retriever.from_documents(chunks, k<span class="op">=</span><span class="dv">3</span>)  <span class="co"># Return top 3 results</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="the-retriever-interface" class="slide level2">
<h2>The Retriever interface</h2>
<p>All LangChain retrievers share the same interface:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a><span class="co"># Returns List[Document]</span></span>
<span id="cb12-2"><a></a>results <span class="op">=</span> retriever.invoke(<span class="st">"search query here"</span>)</span>
<span id="cb12-3"><a></a></span>
<span id="cb12-4"><a></a><span class="cf">for</span> doc <span class="kw">in</span> results:</span>
<span id="cb12-5"><a></a>    <span class="bu">print</span>(doc.page_content[:<span class="dv">100</span>])</span>
<span id="cb12-6"><a></a>    <span class="bu">print</span>(doc.metadata)</span>
<span id="cb12-7"><a></a>    <span class="bu">print</span>(<span class="st">"---"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This uniformity means you can swap BM25 for semantic search later with one line change.</p>
</section>
<section id="putting-it-together" class="slide level2">
<h2>Putting it together</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a><span class="im">from</span> langchain_community.document_loaders <span class="im">import</span> DirectoryLoader, TextLoader</span>
<span id="cb13-2"><a></a><span class="im">from</span> langchain_text_splitters <span class="im">import</span> RecursiveCharacterTextSplitter</span>
<span id="cb13-3"><a></a><span class="im">from</span> langchain_community.retrievers <span class="im">import</span> BM25Retriever</span>
<span id="cb13-4"><a></a></span>
<span id="cb13-5"><a></a><span class="co"># 1. Load documents</span></span>
<span id="cb13-6"><a></a>loader <span class="op">=</span> DirectoryLoader(<span class="st">"./docs"</span>, glob<span class="op">=</span><span class="st">"**/*.txt"</span>, loader_cls<span class="op">=</span>TextLoader)</span>
<span id="cb13-7"><a></a>documents <span class="op">=</span> loader.load()</span>
<span id="cb13-8"><a></a></span>
<span id="cb13-9"><a></a><span class="co"># 2. Split into chunks</span></span>
<span id="cb13-10"><a></a>splitter <span class="op">=</span> RecursiveCharacterTextSplitter(chunk_size<span class="op">=</span><span class="dv">1000</span>, chunk_overlap<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb13-11"><a></a>chunks <span class="op">=</span> splitter.split_documents(documents)</span>
<span id="cb13-12"><a></a></span>
<span id="cb13-13"><a></a><span class="co"># 3. Create retriever</span></span>
<span id="cb13-14"><a></a>retriever <span class="op">=</span> BM25Retriever.from_documents(chunks, k<span class="op">=</span><span class="dv">3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Now <code>retriever.invoke(query)</code> returns the 3 most relevant chunks.</p>
</section>
<section id="part-3-document-qa-agent" class="slide level2">
<h2>Part 3: Document Q&amp;A Agent</h2>
</section>
<section id="combining-chat-search" class="slide level2">
<h2>Combining chat + search</h2>
<div style="text-align: center;">
<p><img data-src="images/06-doc-qa-agent.png" style="width:75.0%"></p>
</div>
<!-- IMAGE: ![](images/06-doc-qa-agent.png){width=70%}

     DESCRIPTION: LangGraph flow diagram for a document Q&A agent.

     PROMPT FOR NANO BANANA PRO: Create a LangGraph-style flow diagram for a document Q&A agent.
     Show: START → "agent" node → conditional diamond "needs search?" → if yes: "tools" node
     (with search_docs label) → back to "agent" → if no: → END. Similar style to tool-calling
     diagrams but with document/search iconography. Clean style with soft colors. -->
<p>The pattern: give the model a <strong>search tool</strong> and let it decide when to use it.</p>
</section>
<section id="search-as-a-tool" class="slide level2">
<h2>Search as a tool</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a><span class="im">from</span> langchain_core.tools <span class="im">import</span> tool</span>
<span id="cb14-2"><a></a></span>
<span id="cb14-3"><a></a><span class="at">@tool</span></span>
<span id="cb14-4"><a></a><span class="kw">def</span> search_docs(query: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb14-5"><a></a>    <span class="co">"""Search documents for information relevant to the query."""</span></span>
<span id="cb14-6"><a></a>    results <span class="op">=</span> retriever.invoke(query)</span>
<span id="cb14-7"><a></a>    <span class="cf">if</span> <span class="kw">not</span> results:</span>
<span id="cb14-8"><a></a>        <span class="cf">return</span> <span class="st">"No relevant documents found."</span></span>
<span id="cb14-9"><a></a>    <span class="cf">return</span> <span class="st">"</span><span class="ch">\n\n</span><span class="st">---</span><span class="ch">\n\n</span><span class="st">"</span>.join(</span>
<span id="cb14-10"><a></a>        <span class="ss">f"Source: </span><span class="sc">{</span>doc<span class="sc">.</span>metadata<span class="sc">.</span>get(<span class="st">'source'</span>, <span class="st">'unknown'</span>)<span class="sc">}</span><span class="ch">\n</span><span class="ss">Content: </span><span class="sc">{</span>doc<span class="sc">.</span>page_content<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb14-11"><a></a>        <span class="cf">for</span> doc <span class="kw">in</span> results</span>
<span id="cb14-12"><a></a>    )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>The tool returns formatted search results that the model can use to answer questions.</p>
</section>
<section id="complete-example-document-qa-agent" class="slide level2">
<h2>Complete example: document Q&amp;A agent</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a><span class="im">from</span> langchain_google_genai <span class="im">import</span> ChatGoogleGenerativeAI</span>
<span id="cb15-2"><a></a><span class="im">from</span> langchain_core.messages <span class="im">import</span> SystemMessage</span>
<span id="cb15-3"><a></a><span class="im">from</span> langchain_core.tools <span class="im">import</span> tool</span>
<span id="cb15-4"><a></a><span class="im">from</span> langgraph.graph <span class="im">import</span> StateGraph, MessagesState, START, END</span>
<span id="cb15-5"><a></a><span class="im">from</span> langgraph.prebuilt <span class="im">import</span> ToolNode, tools_condition</span>
<span id="cb15-6"><a></a></span>
<span id="cb15-7"><a></a>llm <span class="op">=</span> ChatGoogleGenerativeAI(model<span class="op">=</span><span class="st">"gemini-2.5-flash"</span>)</span>
<span id="cb15-8"><a></a></span>
<span id="cb15-9"><a></a>tools <span class="op">=</span> [search_docs]</span>
<span id="cb15-10"><a></a>llm_with_tools <span class="op">=</span> llm.bind_tools(tools)</span>
<span id="cb15-11"><a></a></span>
<span id="cb15-12"><a></a>SYSTEM_PROMPT <span class="op">=</span> <span class="st">"""You are a helpful assistant that answers questions using the provided documents.</span></span>
<span id="cb15-13"><a></a><span class="st">Use the search_docs tool when you need information from the documents to answer the user's question."""</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="complete-example-continued" class="slide level2">
<h2>Complete example (continued)</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a><span class="kw">def</span> agent(state: MessagesState):</span>
<span id="cb16-2"><a></a>    messages <span class="op">=</span> [SystemMessage(content<span class="op">=</span>SYSTEM_PROMPT)] <span class="op">+</span> state[<span class="st">"messages"</span>]</span>
<span id="cb16-3"><a></a>    <span class="cf">return</span> {<span class="st">"messages"</span>: [llm_with_tools.invoke(messages)]}</span>
<span id="cb16-4"><a></a></span>
<span id="cb16-5"><a></a>graph <span class="op">=</span> StateGraph(MessagesState)</span>
<span id="cb16-6"><a></a>graph.add_node(<span class="st">"agent"</span>, agent)</span>
<span id="cb16-7"><a></a>graph.add_node(<span class="st">"tools"</span>, ToolNode(tools))</span>
<span id="cb16-8"><a></a>graph.add_edge(START, <span class="st">"agent"</span>)</span>
<span id="cb16-9"><a></a>graph.add_conditional_edges(<span class="st">"agent"</span>, tools_condition)</span>
<span id="cb16-10"><a></a>graph.add_edge(<span class="st">"tools"</span>, <span class="st">"agent"</span>)</span>
<span id="cb16-11"><a></a>app <span class="op">=</span> graph.<span class="bu">compile</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This is the same pattern from deck 05—but now the tool searches documents.</p>
</section>
<section id="running-the-agent" class="slide level2">
<h2>Running the agent</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a></a><span class="im">from</span> langchain_core.messages <span class="im">import</span> HumanMessage</span>
<span id="cb17-2"><a></a></span>
<span id="cb17-3"><a></a>result <span class="op">=</span> app.invoke({</span>
<span id="cb17-4"><a></a>    <span class="st">"messages"</span>: [HumanMessage(content<span class="op">=</span><span class="st">"How is the database structured?"</span>)]</span>
<span id="cb17-5"><a></a>})</span>
<span id="cb17-6"><a></a></span>
<span id="cb17-7"><a></a><span class="bu">print</span>(result[<span class="st">"messages"</span>][<span class="op">-</span><span class="dv">1</span>].content)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Typically, the agent will:</p>
<ol type="1">
<li>Call <code>search_docs</code> with a relevant query</li>
<li>Read the results</li>
<li>Synthesize an answer</li>
</ol>
</section>
<section id="what-the-model-decides" class="slide level2">
<h2>What the model decides</h2>
<p>The model chooses when to search:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Query</th>
<th>Likely action</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>“How do I run the tests?”</td>
<td>Calls <code>search_docs</code></td>
</tr>
<tr class="even">
<td>“What database does the project use?”</td>
<td>Calls <code>search_docs</code></td>
</tr>
<tr class="odd">
<td>“What’s 2 + 2?”</td>
<td>Answers directly</td>
</tr>
<tr class="even">
<td>“Thanks!”</td>
<td>Responds directly</td>
</tr>
</tbody>
</table>
<p>The system prompt can guide this behavior.</p>
</section>
<section id="multi-turn-document-qa" class="slide level2">
<h2>Multi-turn document Q&amp;A</h2>
<p>Because we’re using <code>MessagesState</code>, conversations work naturally:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a><span class="co"># First question</span></span>
<span id="cb18-2"><a></a>result <span class="op">=</span> app.invoke({<span class="st">"messages"</span>: [</span>
<span id="cb18-3"><a></a>    HumanMessage(content<span class="op">=</span><span class="st">"What testing framework does the project use?"</span>)</span>
<span id="cb18-4"><a></a>]})</span>
<span id="cb18-5"><a></a></span>
<span id="cb18-6"><a></a><span class="co"># Follow-up (pass full history)</span></span>
<span id="cb18-7"><a></a>result <span class="op">=</span> app.invoke({<span class="st">"messages"</span>: result[<span class="st">"messages"</span>] <span class="op">+</span> [</span>
<span id="cb18-8"><a></a>    HumanMessage(content<span class="op">=</span><span class="st">"How do I run the tests?"</span>)</span>
<span id="cb18-9"><a></a>]})</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>The system prompt is prepended inside the <code>agent</code> function — callers just pass messages. The model can reference previous answers and search results.</p>
</section>
<section id="extending-to-semantic-search" class="slide level2">
<h2>Extending to semantic search</h2>
<p>BM25 matches <strong>keywords</strong>. Semantic search matches <strong>meaning</strong>:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Query</th>
<th>BM25 finds</th>
<th>Semantic search finds</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>“car”</td>
<td>Documents with “car”</td>
<td>Documents about automobiles, vehicles</td>
</tr>
<tr class="even">
<td>“happy”</td>
<td>Documents with “happy”</td>
<td>Documents about joy, satisfaction</td>
</tr>
</tbody>
</table>
<p><strong>Coming soon:</strong> Vector embeddings and hybrid retrieval (combining both approaches).</p>
</section>
<section id="best-practices-summary" class="slide level2">
<h2>Best practices summary</h2>
<ol type="1">
<li><strong>Keep conversation history</strong> — pass full message list for multi-turn</li>
<li><strong>Use system prompts</strong> — guide model behavior without storing in state</li>
<li><strong>Chunk appropriately</strong> — balance relevance vs.&nbsp;context (500-1500 chars typical)</li>
<li><strong>Let the model decide</strong> — don’t force search on every query</li>
</ol>
</section>
<section id="key-takeaways" class="slide level2">
<h2>Key takeaways</h2>
<ul>
<li>Multi-turn chat works by <strong>accumulating messages</strong> in <code>MessagesState</code></li>
<li>The model re-reads the full conversation each turn—it doesn’t “remember”</li>
<li>Document retrieval: <strong>load → chunk → retriever → search</strong></li>
<li><code>BM25Retriever</code> provides fast keyword search with a standard interface</li>
<li>A document Q&amp;A agent is just a chatbot with a <strong>search tool</strong></li>
</ul>
</section>
<section id="resources" class="slide level2">
<h2>Resources</h2>
<ul>
<li><a href="https://docs.langchain.com/oss/python/langgraph/overview">LangGraph Overview</a></li>
<li><a href="https://docs.langchain.com/oss/python/integrations/splitters">LangChain Text Splitters</a></li>
<li><a href="https://docs.langchain.com/oss/python/integrations/retrievers/bm25">BM25Retriever</a></li>
<li><a href="https://docs.langchain.com/oss/python/integrations/document_loaders">LangChain Document Loaders</a></li>
</ul>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p><a href="../index.html">Course Home</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/ai-in-the-loop-2026\.github\.io\/ai-in-the-loop-hub\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>