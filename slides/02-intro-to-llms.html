<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.24">

  <meta name="dcterms.date" content="2026-01-15">
  <title>Creating with AI in the Loop – Introduction to Large Language Models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-0fde88a82f0356838740f155f1088782.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Introduction to Large Language Models</h1>

<div class="quarto-title-authors">
</div>

  <p class="date">2026-01-15</p>
</section>
<section id="todays-goals" class="slide level2">
<h2>Today’s goals</h2>
<ul>
<li>Understand what a neural network is (high level)</li>
<li>Learn how transformers work (the architecture behind LLMs)</li>
<li>See how LLMs generate text</li>
<li>Preview A1 — your first Python assignment</li>
</ul>
</section>
<section id="what-is-an-llm" class="slide level2">
<h2>What is an LLM?</h2>
<p>A <strong>Large Language Model</strong> is a neural network trained on massive amounts of text to predict the next word (token).</p>
<ul>
<li>“Large” = billions of parameters (learned weights)</li>
<li>“Language” = trained on text data</li>
<li>“Model” = a mathematical function that maps input → output</li>
</ul>
<p>Examples: GPT-5, Claude, Gemini</p>
</section>
<section id="neural-networks-the-basic-idea" class="slide level2">
<h2>Neural networks: the basic idea</h2>
<p>A neural network is a function that:</p>
<ol type="1">
<li>Takes input (e.g., words, pixels, numbers)</li>
<li>Passes it through layers of simple computations</li>
<li>Produces output (e.g., next word prediction)</li>
</ol>
<p>Each layer transforms the data, learning increasingly abstract patterns.</p>
</section>
<section id="a-single-neuron" class="slide level2">
<h2>A single neuron</h2>

<!-- IMAGE: ![](images/02-neuron.png)

     DESCRIPTION: Diagram of a single neuron with inputs x1, x2, x3, weights w1, w2, w3, bias b,
     summation, activation function, and output. Shows the formula: y = f(Σ(wi*xi) + b)

     PROMPT FOR NANO BANANA PRO: Create a clean diagram of a single artificial neuron. Show 3 inputs
     (x1, x2, x3) on the left, each with a weight (w1, w2, w3) on the connecting lines. These feed
     into a circle (the neuron body) that shows summation (Σ). Add a bias input (b). Show the
     activation function f() applied to the sum, with a single output on the right. Include the
     formula: y = f(Σ(wi*xi) + b). Use a clean, minimal style with soft colors.

     FOLLOW-UP PROMPT: in the previous image of a single artificial neuron: modify the image so that the neuron body (circle) only includes the summation. It should output to f(), which should output to y. Format the formula so that it is prettier and use a \cdot instead of * for the product.

     https://gemini.google.com/app/f7507e36487a8de8?utm_source=app_launcher&utm_medium=owned&utm_campaign=base_all

```
       x₁ ──w₁──╲
                 ╲
       x₂ ──w₂───→ [Σ] → f(·) → output
                 ╱
       x₃ ──w₃──╱
                ↑
               bias
```
-->
<img data-src="images/02-neuron.png" class="r-stretch"><p><strong>Key idea:</strong> Each neuron computes a weighted sum of inputs, then applies an activation function.</p>
</section>
<section id="layers-of-neurons" class="slide level2">
<h2>Layers of neurons</h2>

<!-- IMAGE: ![](images/02-feedforward-network.png)

     DESCRIPTION: Simple feedforward neural network with input layer (4 nodes), hidden layer
     (3 nodes), and output layer (2 nodes). Lines connect every node in adjacent layers.

     PROMPT FOR NANO BANANA PRO: Create a diagram of a simple feedforward neural network. Show
     an input layer with 4 circles on the left, a hidden layer with 3 circles in the middle,
     and an output layer with 2 circles on the right. Draw lines connecting every node in one
     layer to every node in the next layer. Label the layers. Use a clean style with the layers
     in different soft colors. 

     https://gemini.google.com/app/f7507e36487a8de8?utm_source=app_launcher&utm_medium=owned&utm_campaign=base_all

```
  Input        Hidden       Output
  Layer        Layer        Layer

   (•)─────────(•)─────────(•)
    │ ╲       ╱ │ ╲       ╱
   (•)──╳────(•)──╳────(•)
    │ ╱       ╲ │ ╱
   (•)─────────(•)
    │         ╱
   (•)───────╱
```

-->
<img data-src="images/02-feedforward-network.png" class="r-stretch"><ul>
<li>Each connection has a <strong>weight</strong> (learned during training)</li>
<li>The network learns by adjusting weights to minimize prediction errors</li>
</ul>
</section>
<section id="how-neural-networks-learn" class="slide level2">
<h2>How neural networks learn</h2>
<ol type="1">
<li><strong>Forward pass:</strong> Input flows through the network → prediction</li>
<li><strong>Loss calculation:</strong> Compare prediction to correct answer</li>
<li><strong>Backward pass:</strong> Calculate how each weight contributed to the error</li>
<li><strong>Update weights:</strong> Adjust weights to reduce error</li>
<li><strong>Repeat</strong> millions of times on training data</li>
</ol>
<p>This process is called <strong>gradient descent</strong> + <strong>backpropagation</strong>.</p>
</section>
<section id="tokens-not-words" class="slide level2">
<h2>Tokens, not words</h2>
<p>LLMs don’t see words—they see <strong>tokens</strong> (subword pieces):</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Text</th>
<th>Tokens</th>
<th>Token IDs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>“Hello”</td>
<td>[“Hello”]</td>
<td>[13225]</td>
</tr>
<tr class="even">
<td>“unhappiness”</td>
<td>[“un”, “h”, “appiness”]</td>
<td>[373, 71, 117779]</td>
</tr>
<tr class="odd">
<td>“ChatGPT”</td>
<td>[“Chat”, “GPT”]</td>
<td>[14065, 162016]</td>
</tr>
</tbody>
</table>
<p><strong>Why?</strong> Handles rare words, typos, new words efficiently.</p>
<p>Each token is represented by a unique token ID (positive integer)</p>
<p>Typical vocab: 100,000+ tokens</p>
</section>
<section id="from-basic-networks-to-transformers" class="slide level2">
<h2>From basic networks to transformers</h2>
<p>Early neural networks for language had problems:</p>
<ul>
<li><strong>Recurrent networks (RNNs):</strong> Process tokens sequentially → hard to parallelize, long-range dependencies can be difficult</li>
<li><strong>Attention breakthrough (2017):</strong> Process tokens in parallel; for each token compute attention weights over other tokens to combine the most relevant context</li>
</ul>
<p>The <strong>Transformer</strong> architecture uses attention to handle long text efficiently</p>
</section>
<section id="the-transformer-key-components" class="slide level2">
<h2>The transformer: key components</h2>
<div style="text-align: center;">
<p><img data-src="images/02-transformer-pipeline.png" style="width:85.0%"></p>
</div>
<!-- IMAGE: ![](images/02-transformer-pipeline.png){width="90%"}

     DESCRIPTION: End-to-end transformer pipeline showing the full flow from tokens to output.

     PROMPT FOR NANO BANANA PRO: Create a horizontal pipeline diagram for a transformer LLM.
     Show boxes connected by arrows in this order: "Tokens" → "Embeddings + Position" →
     a box labeled "Transformer Blocks (×N)" containing "Self-Attention" and "Feed-Forward" stacked →
     "Linear + Softmax" → "Next Token Probs". Use clean boxes with rounded corners
     and soft colors. Make the transformer blocks box slightly larger to show it repeats.

```
┌────────┐   ┌─────────────────┐   ┌─────────────────────────┐   ┌───────────────┐   ┌─────────────┐
│ Tokens │ → │ Embeddings +    │ → │  Transformer Blocks(×N) │ → │ Linear +      │ → │ Next Token  │
│        │   │ Position Info   │   │  ┌─────────────────┐    │   │ Softmax       │   │ Probs       │
└────────┘   └─────────────────┘   │  │ Self-Attention  │    │   └───────────────┘   └─────────────┘
                                   │  │ Feed-Forward    │    │
                                   │  └─────────────────┘    │
                                   └─────────────────────────┘
```
-->
<ul>
<li><strong>Embeddings + Position:</strong> Convert token IDs to vectors, add position information</li>
<li><strong>Transformer Blocks:</strong> Repeated layers of attention + feed-forward (dozens of these)</li>
<li><strong>Output:</strong> Probability distribution over all possible next tokens</li>
</ul>
</section>
<section id="embeddings-tokens-as-vectors" class="slide level2">
<h2>Embeddings: tokens as vectors</h2>
<p>Each token maps to a <strong>vector</strong> (list of numbers):</p>
<pre><code>"cat" → [0.2, -0.5, 0.8, 0.1, ...]   
"dog" → [0.3, -0.4, 0.7, 0.2, ...]   (similar to "cat")
"run" → [-0.1, 0.9, -0.3, 0.6, ...]  (different direction)</code></pre>
<ul>
<li>Embeddings are vectors in <span class="math inline">\(\mathbb{R}^d\)</span> (<span class="math inline">\(d\)</span> typically in the thousands)</li>
<li>Similar words have similar vectors</li>
<li>Embeddings are <strong>learned</strong> during training</li>
<li>Sequence of <span class="math inline">\(L\)</span> input tokens → <span class="math inline">\(L\)</span> vectors → <span class="math inline">\(L\times d\)</span> input matrix</li>
</ul>
</section>
<section id="positional-encoding" class="slide level2">
<h2>Positional encoding</h2>
<p>Transformers process tokens in parallel—but token order matters!</p>
<p><em>“The cat chased the dog”</em> ≠ <em>“The dog chased the cat”</em></p>
<p><strong>Solution:</strong> Inject position info into each token representation.</p>
<ul>
<li>Each position gets its own positional encoding (e.g., a vector for position 1, 2, 3, …)</li>
<li>Often <strong>added</strong> to the token embedding<br>
<em>(some modern LLMs encode position inside the attention computation instead)</em></li>
<li>This gives the model the information it needs to learn how order affects meaning</li>
</ul>
</section>
<section id="self-attention-how-tokens-share-information" class="slide level2">
<h2>Self-attention: how tokens share information</h2>
<p>For each token, the model computes <strong>attention weights</strong> over other tokens, then forms a new representation as a <strong>weighted mix</strong> of their information.</p>
<p><em>“The cat sat on the mat because it was tired.”</em><br>
To interpret <strong>“it”</strong>, the model should weight <strong>“cat”</strong> more than <strong>“mat”</strong>.</p>
<p>This happens <strong>for every token</strong>, in every transformer block.</p>
</section>
<section id="attention-visualized" class="slide level2">
<h2>Attention visualized</h2>

<!-- IMAGE: ![](images/02-attention-heatmap.png)

     DESCRIPTION: Attention heatmap for "The cat sat on the mat" showing which words attend
     to which other words. 6x6 grid with color intensity indicating attention weights.

     PROMPT FOR NANO BANANA PRO: Create an attention visualization heatmap for the sentence
     "The cat sat on the mat". Show a 6x6 grid where rows and columns are both labeled with
     the words. Use color intensity to show attention weights - darker means stronger attention.
     Make "cat" strongly attend to "The" and itself. Make "sat" attend to "cat". Make "mat"
     attend to "the" (second one) and "on". Use a blue color gradient. Include a legend.

     REVISED PROMPT: Create an attention (e.g., for a transformer model) visualization heatmap for the sentence "The cat sat on the mat because it was tired". Show a 10x10 grid where rows and columns are both labeled with the words. Use color intensity to show attention weights - darker means stronger attention. Use a blue color gradient. Include a legend.

     https://gemini.google.com/app/08626c2583eff1c8?utm_source=app_launcher&utm_medium=owned&utm_campaign=base_all

```
          The   cat   sat   on   the   mat
    The   ███   ░░░   ░░░   ░░░   ░░░   ░░░
    cat   ██░   ███   ░░░   ░░░   ░░░   ░░░
    sat   ░░░   ██░   ███   ░░░   ░░░   ░░░
    on    ░░░   ░░░   █░░   ███   ░░░   ░░░
    the   ░░░   ░░░   ░░░   ██░   ███   ░░░
    mat   ░░░   ░░░   ░░░   █░░   ██░   ███
```
-->
<img data-src="images/02-attention-heatmap.png" class="r-stretch"><p>Each token’s representation is updated by combining information from other tokens via learned weights.</p>
</section>
<section id="how-llms-generate-text" class="slide level2">
<h2>How LLMs generate text</h2>
<ol type="1">
<li><strong>Input:</strong> “The weather today is”</li>
<li><strong>Model predicts</strong> probability distribution over all tokens</li>
<li><strong>Sample</strong> next token: “sunny” (p=0.3), “cold” (p=0.2), “nice” (p=0.15)…</li>
<li><strong>Append</strong> chosen token: “The weather today is sunny”</li>
<li><strong>Repeat</strong> until done</li>
</ol>
<p>This is <strong>autoregressive generation</strong>—each token depends on all previous tokens.</p>
</section>
<section id="randomness" class="slide level2">
<h2>Randomness</h2>
<ul>
<li>At inference the transformer’s forward pass is <strong>deterministic</strong></li>
<li>After probabilities have been computed, the next token is chosen using a random draw according to the probabilities</li>
</ul>
</section>
<section id="temperature-and-sampling" class="slide level2">
<h2>Temperature and sampling</h2>
<p><strong>Temperature</strong> flattens (<span class="math inline">\(T&gt;1\)</span>) or sharpens (<span class="math inline">\(T&lt;1\)</span>) the probability distribution</p>
<ul>
<li><strong>Low (0.0–0.3):</strong> More deterministic, picks highest probability</li>
<li><strong>Medium (0.5–0.7):</strong> Balanced creativity and coherence</li>
<li><strong>High (0.8–1.0+):</strong> More random, creative, sometimes nonsensical</li>
</ul>
<pre><code>Temperature 0.1: "The cat sat on the mat."
Temperature 0.7: "The cat lounged on the soft carpet."
Temperature 1.2: "The cat philosophized atop the cosmic rug."</code></pre>
</section>
<section id="key-takeaways" class="slide level2">
<h2>Key takeaways</h2>
<ul>
<li>Neural networks learn patterns by adjusting weights</li>
<li><strong>Transformers</strong> use self-attention to understand context</li>
<li>LLMs predict the <strong>next token</strong> based on all previous tokens</li>
<li>Generation is <strong>probabilistic</strong>—same prompt can give different outputs</li>
<li><strong>Temperature</strong> controls creativity vs.&nbsp;consistency</li>
</ul>
</section>
<section id="a1-mock-llm-chat" class="slide level2">
<h2>A1 — Mock LLM Chat</h2>
<p>Your first Python assignment builds a <strong>chat application</strong> structure:</p>
<ul>
<li>Set up Python environment (<code>.venv</code>, dependencies)</li>
<li>Use <strong>LangGraph</strong> to structure conversation flow</li>
<li>Build a simple <strong>command-line interface (CLI)</strong></li>
<li>Use a <strong>mock model</strong> (no API calls yet)</li>
</ul>
</section>
<section id="why-a-mock-model" class="slide level2">
<h2>Why a mock model?</h2>
<ul>
<li>Focus on <strong>structure and workflow</strong> first</li>
<li>No API keys or costs to worry about</li>
<li>Predictable behavior for testing</li>
<li><strong>A2</strong> will connect to a real LLM via API</li>
</ul>
<p>This pattern (mock → real) is common in software development!</p>
</section>
<section id="a1-setup-overview" class="slide level2">
<h2>A1 setup overview</h2>
<p><strong>Follow GitHub Classroom Workflow Instructions</strong></p>
<ol type="1">
<li>Accept A1 from GitHub Classroom</li>
<li>Clone the repo</li>
<li>Create virtual environment</li>
<li>Activate it and install dependencies</li>
<li>Follow the README to complete the assignment</li>
</ol>
</section>
<section id="ai-dev-log" class="slide level2">
<h2>AI Dev Log</h2>
<ul>
<li>Starting with A1 you will complete an <em>AI Dev Log</em> for each build assignment</li>
<li>Look for it in the <code>docs</code> folder in the repo</li>
<li>Some entries probably won’t be relevant for A1–write: “none” or “NA”</li>
</ul>
<pre><code>## Entry N - [Brief title]

**Date:** YYYY-MM-DD
**Goal:** [What you were trying to accomplish]
**Tool used:** [e.g., ChatGPT, Claude, Copilot, none]
**Prompt/Question:** [What you asked the AI, or describe the problem]
**AI Response:** [Key suggestions or guidance received]
**Changes Made:** [Actual code/files modified]
**Testing:** [How you verified it works]
**Result:** [Did it work? Any issues?]</code></pre>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p><a href="../index.html">Course Home</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/ai-in-the-loop-2026\.github\.io\/ai-in-the-loop-hub\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>